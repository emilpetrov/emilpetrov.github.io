{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os.path\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMonthOfData(month):\n",
    "\turl = 'http://www.emi.ea.govt.nz/Reports/VisualTable'\\\n",
    "\t'?reportName=VB5YEV&categoryName=Retail&reportGroupIndex=5'\\\n",
    "\t'&reportDisplayContext=Gallery&eventMode=Sync&reportType=VisualTable'\\\n",
    "\t'&param_DateFrom='+month.start_time.strftime('%d/%m/%Y')+\\\n",
    "\t'&param_DateTo='+month.end_time.strftime('%d/%m/%Y')+\\\n",
    "\t'&param_RegionType=REG_COUNCIL'\\\n",
    "\t'&param_RetailEntity=Trader'\\\n",
    "\t'&param_MarketSegment=All'\\\n",
    "\t'&param_Show=All'\n",
    "\n",
    "\t#url2 = 'http://www.emi.ea.govt.nz/Reports/VisualTable?reportName=VB5YEV&categoryName=Retail&reportGroupIndex=5&reportDisplayContext=Gallery&eventMode=Sync&reportType=VisualTable&param_DateFrom=01/02/2016&param_DateTo=29/02/2016&param_RegionType=NWK_REPORTING_REGION_DIST&param_RetailEntity=Trader&param_MarketSegment=All&param_Show=All'\n",
    "\t\t\n",
    "\tpage = urllib2.urlopen(url).read()\n",
    "\tsoup = BeautifulSoup(page,\"lxml\")\n",
    "\ttable=soup.find(id=\"tableReport_DXMainTable\")\n",
    "\n",
    "\t#scrape retailer names, note first column='Total' and each column has three TDs: Gains, Losses, Net \n",
    "\tretailers=[]\n",
    "\ti=0\n",
    "\ttr=table.find('tr',id=\"tableReport_DXHeadersRow0\")\n",
    "\tfor td in tr.find_all('td'):\n",
    "\t\tif (i!=1) and ((i-1)%3 ==0):\t#we want i=4,7,10 etc but not i=1\n",
    "\t\t\t#print \"%s: %s\" % (j, td.text)\n",
    "\t\t\tretailers.append(td.text)\n",
    "\t\ti+=1\n",
    "\t#print \"retailers: %s; %s\" % (len(retailers), retailers)\n",
    "\n",
    "\t#scrape region names\n",
    "\tregions=[]\n",
    "\tfor tr in table.find_all('tr',class_=\"dxgvDataRow\"):\n",
    "\t\tregions.append(tr.find('td').text) #it's always the first td in the tr\n",
    "\t#print \"regions: %s; %s\" % (len(regions), regions)\n",
    "\n",
    "\t#scrape data cells, note it will be 3*toprow wide and leftcol tall\n",
    "\t#gains = np.zeros([len(regions),len(retailers)], dtype=int)\n",
    "\tgains = np.zeros([len(regions),len(retailers)], dtype=int)\n",
    "\tlosses = np.zeros([len(regions),len(retailers)], dtype=int)\n",
    "\tnet = np.zeros([len(regions),len(retailers)], dtype=int)\n",
    "\t#gains[:]=losses[:]=net[:]=np.NaN\n",
    "\n",
    "\ti=0\n",
    "\tfor tr in table.find_all('tr',class_=\"dxgvDataRow\"):\n",
    "\t#\tprint \"tr %s has %s tds\" % (i, len(tr.find_all('td')))\n",
    "\t\tj=k=0\n",
    "\t\tfor td in tr.find_all('td'):\n",
    "\t#\t\tprint \"i %s j %s k %s td %s\" % (i,j,k, td.text)\n",
    "\t\t\tif not td.text:\t\t\t\t#empty string, move on\n",
    "\t\t\t\tpass\n",
    "\t\t\telif k == 0:\t\t\t\t#k0=Auckland, k1=gains k2=losses, k3=net, k4=gains, etc\n",
    "\t\t\t\tpass\n",
    "\t\t\telif k%3 == 1:\n",
    "\t\t\t\tgains[i,j]=int(td.text.replace(',',''))\n",
    "\t\t\t\t#print \"i %s j %s k %s td %s \" % (i,j,k,td.text)\n",
    "\t\t\t\t#print gains[i,]\n",
    "\t\t\telif k%3 == 2:\n",
    "\t\t\t\tlosses[i,j]=int(td.text.replace(',',''))\n",
    "\t\t\telif k%3 == 0:\n",
    "\t\t\t\tnet[i,j]=int(td.text.replace(',',''))\n",
    "\t\t\t\tj+=1\n",
    "\t\t\tk+=1\n",
    "\n",
    "\t\ti+=1\n",
    "\n",
    "\tgains=pd.DataFrame(gains,index=regions,columns=retailers)\n",
    "\tgains=gains.unstack().reset_index(name='gains')\n",
    "\tgains.rename(columns={'level_0': 'retailer', 'level_1':'region'}, inplace=True)\n",
    "\n",
    "\tlosses=pd.DataFrame(losses,index=regions,columns=retailers)\n",
    "\tlosses=losses.unstack().reset_index(name='losses')\n",
    "\tlosses.rename(columns={'level_0': 'retailer', 'level_1':'region'}, inplace=True)\n",
    "\n",
    "\tnet=pd.DataFrame(net,index=regions,columns=retailers)\n",
    "\tnet=net.unstack().reset_index(name='net')\n",
    "\tnet.rename(columns={'level_0': 'retailer', 'level_1':'region'}, inplace=True)\n",
    "\n",
    "\tdf=pd.merge(gains,pd.merge(losses,net))\n",
    "\tdf['month']=month #pd.Period(start.strftime('%Y-%m','M')\n",
    "\tprint '%s has %s rows x %s columns' % (month, len(df), len(df.columns))\n",
    "\treturn df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-01 has 224 rows x 6 columns\n",
      "2010-02 has 224 rows x 6 columns\n",
      "2010-03 has 240 rows x 6 columns\n",
      "2010-04 has 224 rows x 6 columns\n",
      "2010-05 has 224 rows x 6 columns\n",
      "2010-06 has 240 rows x 6 columns\n",
      "2010-07 has 240 rows x 6 columns\n",
      "2010-08 has 256 rows x 6 columns\n",
      "2010-09 has 240 rows x 6 columns\n",
      "2010-10 has 240 rows x 6 columns\n",
      "2010-11 has 240 rows x 6 columns\n",
      "2010-12 has 240 rows x 6 columns\n",
      "2011-01 has 224 rows x 6 columns\n",
      "2011-02 has 224 rows x 6 columns\n",
      "2011-03 has 240 rows x 6 columns\n",
      "2011-04 has 256 rows x 6 columns\n",
      "2011-05 has 224 rows x 6 columns\n",
      "2011-06 has 240 rows x 6 columns\n",
      "2011-07 has 240 rows x 6 columns\n",
      "2011-08 has 240 rows x 6 columns\n",
      "2011-09 has 240 rows x 6 columns\n",
      "2011-10 has 256 rows x 6 columns\n",
      "2011-11 has 256 rows x 6 columns\n",
      "2011-12 has 272 rows x 6 columns\n",
      "2012-01 has 256 rows x 6 columns\n",
      "2012-02 has 272 rows x 6 columns\n",
      "2012-03 has 272 rows x 6 columns\n",
      "2012-04 has 272 rows x 6 columns\n",
      "2012-05 has 288 rows x 6 columns\n",
      "2012-06 has 288 rows x 6 columns\n",
      "2012-07 has 256 rows x 6 columns\n",
      "2012-08 has 272 rows x 6 columns\n",
      "2012-09 has 256 rows x 6 columns\n",
      "2012-10 has 272 rows x 6 columns\n",
      "2012-11 has 288 rows x 6 columns\n",
      "2012-12 has 272 rows x 6 columns\n",
      "2013-01 has 272 rows x 6 columns\n",
      "2013-02 has 304 rows x 6 columns\n",
      "2013-03 has 288 rows x 6 columns\n",
      "2013-04 has 272 rows x 6 columns\n",
      "2013-05 has 288 rows x 6 columns\n",
      "2013-06 has 304 rows x 6 columns\n",
      "2013-07 has 304 rows x 6 columns\n",
      "2013-08 has 304 rows x 6 columns\n",
      "2013-09 has 304 rows x 6 columns\n",
      "2013-10 has 304 rows x 6 columns\n",
      "2013-11 has 320 rows x 6 columns\n",
      "2013-12 has 320 rows x 6 columns\n",
      "2014-01 has 336 rows x 6 columns\n",
      "2014-02 has 336 rows x 6 columns\n",
      "2014-03 has 320 rows x 6 columns\n",
      "2014-04 has 304 rows x 6 columns\n",
      "2014-05 has 320 rows x 6 columns\n",
      "2014-06 has 320 rows x 6 columns\n",
      "2014-07 has 320 rows x 6 columns\n",
      "2014-08 has 320 rows x 6 columns\n",
      "2014-09 has 320 rows x 6 columns\n",
      "2014-10 has 320 rows x 6 columns\n",
      "2014-11 has 368 rows x 6 columns\n",
      "2014-12 has 352 rows x 6 columns\n",
      "2015-01 has 384 rows x 6 columns\n",
      "2015-02 has 384 rows x 6 columns\n",
      "2015-03 has 400 rows x 6 columns\n",
      "2015-04 has 384 rows x 6 columns\n",
      "2015-05 has 400 rows x 6 columns\n",
      "2015-06 has 400 rows x 6 columns\n",
      "2015-07 has 400 rows x 6 columns\n",
      "2015-08 has 416 rows x 6 columns\n",
      "2015-09 has 416 rows x 6 columns\n",
      "2015-10 has 400 rows x 6 columns\n",
      "2015-11 has 432 rows x 6 columns\n",
      "2015-12 has 432 rows x 6 columns\n",
      "2016-01 has 432 rows x 6 columns\n",
      "2016-02 has 448 rows x 6 columns\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('df.pickle'):\n",
    "\tdf = pickle.load(open('df.pickle'))\n",
    "else:\n",
    "\tmonths = pd.period_range('2010-01','2016-02',freq='M')\n",
    "\tfor m in months:\n",
    "\t\tif 'df' not in locals():\n",
    "\t\t\tdf = getMonthOfData(m)\n",
    "\t\telse:\n",
    "\t\t\tdf = pd.concat([df,getMonthOfData(m)])\n",
    "\t\tdf.to_pickle('df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.figure(); df['retailer'=='Total'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2010', periods=1000))\n",
    "#ts = ts.cumsum()\n",
    "#ts.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df2 = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD'))\n",
    "#df2 = df2.cumsum()\n",
    "#plt.figure()\n",
    "#df2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
